{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask[dataframe]\n",
      "  Downloading dask-0.17.1-py2.py3-none-any.whl (577kB)\n",
      "\u001b[K    100% |################################| 583kB 2.2MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy; extra == \"dataframe\" in /usr/local/lib/python3.5/dist-packages (from dask[dataframe])\n",
      "Requirement already satisfied: pandas>=0.19.0; extra == \"dataframe\" in /usr/local/lib/python3.5/dist-packages (from dask[dataframe])\n",
      "Collecting toolz>=0.7.3; extra == \"dataframe\" (from dask[dataframe])\n",
      "  Downloading toolz-0.9.0.tar.gz (45kB)\n",
      "\u001b[K    100% |################################| 51kB 10.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle>=0.2.1; extra == \"dataframe\" (from dask[dataframe])\n",
      "  Downloading cloudpickle-0.5.2-py2.py3-none-any.whl\n",
      "Collecting partd>=0.3.8; extra == \"dataframe\" (from dask[dataframe])\n",
      "  Downloading partd-0.3.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.5/dist-packages (from pandas>=0.19.0; extra == \"dataframe\"->dask[dataframe])\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas>=0.19.0; extra == \"dataframe\"->dask[dataframe])\n",
      "Collecting locket (from partd>=0.3.8; extra == \"dataframe\"->dask[dataframe])\n",
      "  Downloading locket-0.2.0.tar.gz\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2->pandas>=0.19.0; extra == \"dataframe\"->dask[dataframe])\n",
      "Building wheels for collected packages: toolz, locket\n",
      "  Running setup.py bdist_wheel for toolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/57/51/8a/433a9c0a2c65fc1b2a795ae036b932f3339a02e9ae88367659\n",
      "  Running setup.py bdist_wheel for locket ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/7a/de/da/8039d7d9547aabfb95f2deca20948c8eb4c71c3b85405547c2\n",
      "Successfully built toolz locket\n",
      "Installing collected packages: toolz, cloudpickle, locket, partd, dask\n",
      "Successfully installed cloudpickle-0.5.2 dask-0.17.1 locket-0.2.0 partd-0.3.8 toolz-0.9.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.19.8-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |################################| 61kB 5.6MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.19.8\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"dask[dataframe]\"\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import h5py as h5\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start client\n",
    "# client = Client('10.70.1.160:8786')\n",
    "# client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "DATA_PATH = r'data/eightieth.h5' # Path to the learning dataset\n",
    "CHUNK_SIZE = 15000 # Number of images to process in one batch (must fit comfortably in memory)\n",
    "TRAIN_SIZE = 7/8 # Size of the train dataset (compared to the total dataset)\n",
    "\n",
    "\n",
    "# data_h5 = h5.File('data/eightieth.h5', mode='r')\n",
    "# landcover = da.from_array(data_h5['TOP_LANDCOVER'], chunks=(1000,1))\n",
    "# images = da.from_array(data_h5['S2'], chunks=(1000,16,16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup generator yielding X, y chunks (default size 1000)\n",
    "\n",
    "classes = da.unique(da.from_array(h5.File(DATA_PATH)['TOP_LANDCOVER'], chunks=(CHUNK_SIZE,1))).compute()\n",
    "\n",
    "def generator(h5_path, chunk_size, train_size):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    X = f['S2']\n",
    "    y = f['TOP_LANDCOVER']\n",
    "    \n",
    "    # Compute number of chunks needed\n",
    "    no_chunks = len(X) // chunk_size\n",
    "    if len(X) % chunk_size > 0:\n",
    "        # len(X) is not an exact multiple of chunk_size\n",
    "        no_chunks += 1\n",
    "    \n",
    "    print(len(X), '-', no_chunks)\n",
    "    for c in range(no_chunks):\n",
    "        X_to_yield = X[c*chunk_size:(c+1)*chunk_size,:,:,:]\n",
    "        y_to_yield = y[c*chunk_size:(c+1)*chunk_size,:]\n",
    "        \n",
    "        # Wrangle data\n",
    "        X_to_yield = np.array(X_to_yield).reshape((-1, 16*16*4)) # Flatten each element in the array\n",
    "        y_to_yield = np.array(y_to_yield).astype(int).reshape((-1,))\n",
    "        y_to_yield = label_binarize(y_to_yield, classes=classes)\n",
    "        \n",
    "        \n",
    "        yield train_test_split(X_to_yield, y_to_yield, train_size=train_size, test_size=1-train_size)\n",
    "    \n",
    "# Test\n",
    "# for X, y in generator('data/eightieth.h5', 1000):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234000 - 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:51,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.4153444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "forests_list = [] # List of forests to aggregate\n",
    "\n",
    "for X_train, X_test, y_train, y_test in tqdm(generator(DATA_PATH, CHUNK_SIZE, TRAIN_SIZE)):\n",
    "    cf = RandomForestClassifier(n_estimators=20, n_jobs=-1) # parameters to define\n",
    "    cf.fit(X=X_train, y=y_train)\n",
    "    \n",
    "#     Reshape y_test to make it understandable (1D series)\n",
    "    score = cf.score(X_test, y_test)\n",
    "    \n",
    "    forests_list.append((cf, score))\n",
    "    \n",
    "forests_list = np.array(forests_list)\n",
    "print('Mean score:', forests_list[:,1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom VotingClassifier\n",
    "# Can ensemble pre-fitted models (as opposed to sklearn's implementation which needs retraining)\n",
    "\n",
    "class VotingClassifier:\n",
    "    # Two voting modes :\n",
    "        # - Hard: the majority wins, if there's a tie, a contender is selected randomly\n",
    "        # - Soft: use the provided weights and tally the weighted votes to determine winners. Weights must have shape (len(estimators))\n",
    "    \n",
    "    def __init__(self, estimators, classes=None, weights=None):\n",
    "        # estimators: iterable of estimators implementing the predict() API\n",
    "        # weights: iterable of (numeric) weights\n",
    "        # classes: list of matching classes\n",
    "        \n",
    "        self.estimators = estimators\n",
    "        self.weights = np.array(weights)\n",
    "        self.n_classes = len(self.estimators[0].n_classes_)\n",
    "        \n",
    "    \n",
    "    def _special_argmax(self, pred):\n",
    "        # Compute the usual argmax along the lines\n",
    "        # For each null predictions ([0]*no_features), replace the argmax with -1 to filter it easily\n",
    "        # Having an argmax of 0 then actually means that the predicted label is the #0\n",
    "\n",
    "        # pred shape=(no_classifiers, no_features)\n",
    "        out = pred.argmax(axis=1)\n",
    "        out[np.all(pred==-1.0, axis=1)] = self.n_classes + 1\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X is of shape (no_samples, no_features)\n",
    "        # Return array of shape (no_samples,)\n",
    "\n",
    "        predictions = np.empty((len(self.estimators), X.shape[0], self.n_classes))\n",
    "        \n",
    "        for i, clf in enumerate(self.estimators):\n",
    "            predictions[i, :, :] = clf.predict(X)\n",
    "            \n",
    "        # predictions is of shape (no_classifiers, no_samples, no_features)\n",
    "        \n",
    "        out = np.zeros((X.shape[0],)) # out matrix\n",
    "        \n",
    "        for k in range(predictions.shape[1]):\n",
    "            arr = predictions[:, k, :]\n",
    "            \n",
    "            # Replace all the 0 to -1 (in order to filter out the null prediction later on)\n",
    "            np.place(arr, arr==0.0, -1)\n",
    "            \n",
    "            arr_label = self._special_argmax(arr)\n",
    "            \n",
    "            idx_label = ~(arr_label == self.n_classes + 1)\n",
    "            \n",
    "            arr_label = arr_label[idx_label]\n",
    "\n",
    "            if len(arr_label) == 0:\n",
    "                # If an image cannot be predicted at all by any estimator, we simply affect it a random class unfortunately\n",
    "                choice = np.random.choice(range(self.n_classes))\n",
    "                print('Unpredictable image at index {}, affected class -> {}'.format(k, choice))\n",
    "                out[k] = choice\n",
    "                continue\n",
    "            \n",
    "            out[k] = np.argmax(np.bincount(arr_label, \n",
    "                                           weights=weights[idx_label]))\n",
    "            \n",
    "        return out    \n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # Convert y to its category label\n",
    "        y = y.argmax(axis=1)\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        fbeta = fbeta_score(y, y_pred, 2, average='macro')\n",
    "        \n",
    "        print('Accuracy :', accuracy)\n",
    "        print('F2 score :', fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpredictable image at index 11, affected class -> 0\n",
      "Unpredictable image at index 25, affected class -> 9\n",
      "Unpredictable image at index 36, affected class -> 8\n",
      "Unpredictable image at index 56, affected class -> 2\n",
      "Unpredictable image at index 68, affected class -> 9\n",
      "Unpredictable image at index 71, affected class -> 11\n",
      "Unpredictable image at index 74, affected class -> 9\n",
      "Unpredictable image at index 78, affected class -> 7\n",
      "Unpredictable image at index 97, affected class -> 3\n",
      "Unpredictable image at index 101, affected class -> 1\n",
      "Unpredictable image at index 173, affected class -> 11\n",
      "Unpredictable image at index 178, affected class -> 1\n",
      "Unpredictable image at index 198, affected class -> 3\n",
      "Unpredictable image at index 203, affected class -> 3\n",
      "Unpredictable image at index 212, affected class -> 2\n",
      "Unpredictable image at index 213, affected class -> 10\n",
      "Unpredictable image at index 232, affected class -> 8\n",
      "Unpredictable image at index 237, affected class -> 7\n",
      "Unpredictable image at index 239, affected class -> 3\n",
      "Unpredictable image at index 243, affected class -> 11\n",
      "Unpredictable image at index 268, affected class -> 4\n",
      "Unpredictable image at index 271, affected class -> 11\n",
      "Unpredictable image at index 331, affected class -> 1\n",
      "Unpredictable image at index 363, affected class -> 5\n",
      "Unpredictable image at index 373, affected class -> 4\n",
      "Unpredictable image at index 405, affected class -> 8\n",
      "Unpredictable image at index 418, affected class -> 10\n",
      "Unpredictable image at index 437, affected class -> 4\n",
      "Unpredictable image at index 459, affected class -> 4\n",
      "Unpredictable image at index 480, affected class -> 9\n",
      "Unpredictable image at index 481, affected class -> 1\n",
      "Unpredictable image at index 495, affected class -> 5\n",
      "Unpredictable image at index 501, affected class -> 9\n",
      "Unpredictable image at index 503, affected class -> 1\n",
      "Unpredictable image at index 505, affected class -> 3\n",
      "Unpredictable image at index 520, affected class -> 12\n",
      "Unpredictable image at index 546, affected class -> 8\n",
      "Unpredictable image at index 565, affected class -> 11\n",
      "Unpredictable image at index 603, affected class -> 5\n",
      "Unpredictable image at index 613, affected class -> 6\n",
      "Unpredictable image at index 617, affected class -> 12\n",
      "Unpredictable image at index 642, affected class -> 11\n",
      "Unpredictable image at index 652, affected class -> 1\n",
      "Unpredictable image at index 670, affected class -> 10\n",
      "Unpredictable image at index 680, affected class -> 2\n",
      "Unpredictable image at index 711, affected class -> 11\n",
      "Unpredictable image at index 715, affected class -> 7\n",
      "Unpredictable image at index 733, affected class -> 7\n",
      "Unpredictable image at index 737, affected class -> 10\n",
      "Unpredictable image at index 741, affected class -> 8\n",
      "Unpredictable image at index 749, affected class -> 9\n",
      "Unpredictable image at index 752, affected class -> 3\n",
      "Unpredictable image at index 758, affected class -> 4\n",
      "Unpredictable image at index 770, affected class -> 0\n",
      "Unpredictable image at index 776, affected class -> 2\n",
      "Unpredictable image at index 790, affected class -> 5\n",
      "Unpredictable image at index 801, affected class -> 7\n",
      "Unpredictable image at index 824, affected class -> 3\n",
      "Unpredictable image at index 842, affected class -> 10\n",
      "Unpredictable image at index 854, affected class -> 12\n",
      "Unpredictable image at index 861, affected class -> 2\n",
      "Unpredictable image at index 865, affected class -> 1\n",
      "Unpredictable image at index 882, affected class -> 0\n",
      "Unpredictable image at index 883, affected class -> 5\n",
      "Unpredictable image at index 894, affected class -> 12\n",
      "Unpredictable image at index 924, affected class -> 10\n",
      "Unpredictable image at index 943, affected class -> 10\n",
      "Unpredictable image at index 953, affected class -> 5\n",
      "Unpredictable image at index 961, affected class -> 4\n",
      "Unpredictable image at index 980, affected class -> 3\n",
      "Unpredictable image at index 981, affected class -> 12\n",
      "Unpredictable image at index 989, affected class -> 2\n",
      "Unpredictable image at index 999, affected class -> 5\n",
      "Unpredictable image at index 1006, affected class -> 0\n",
      "Unpredictable image at index 1022, affected class -> 9\n",
      "Unpredictable image at index 1031, affected class -> 2\n",
      "Unpredictable image at index 1037, affected class -> 4\n",
      "Unpredictable image at index 1085, affected class -> 6\n",
      "Unpredictable image at index 1118, affected class -> 12\n",
      "Unpredictable image at index 1119, affected class -> 8\n",
      "Accuracy : 0.49866666666666665\n",
      "F2 score : 0.19571882956888176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "weights = forests_list[:,1].astype(float)\n",
    "vc = VotingClassifier(forests_list[:,0], weights=weights)\n",
    "# predictions = vc.predict(X_test)\n",
    "vc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vc_20trees_eigtieth.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the model to the disk\n",
    "joblib.dump(vc, 'vc_20trees_eigtieth.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
