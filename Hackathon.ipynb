{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon\n",
    "\n",
    "Some utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tables in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.5/dist-packages (from tables)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.5/dist-packages (from tables)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from tables)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables\n",
    "\n",
    "PATH_DATA = '/notebooks/data/equi_Groupe6.h5'\n",
    "PATH_PREDICT_WITHOUT_GT = '/notebooks/data/pred_students/pred_from_half/pred_eighties_from_half_1_without_gt.h5'\n",
    "PATH_SUBMIT = '/notebooks/ChallengeHacka/pred_eighties_from_half_1_gr6.csv'\n",
    "# PATH_PREDICT_WITH_GT = '/pred_teachers/pred_eighties_from_half_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout\n",
    "import keras.layers.normalization \n",
    "from keras.callbacks import Callback\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs(h5_path):\n",
    "    f = h5.File(h5_path)\n",
    "    return range(len(f['S2']))\n",
    "\n",
    "def shuffle_idx(sample_idxs):\n",
    "    return list(np.random.permutation(sample_idxs))\n",
    "\n",
    "def split_train_val(sample_idxs, proportion):\n",
    "    n_samples = len(sample_idxs)\n",
    "    return sample_idxs[:int((1.-proportion)*n_samples)], sample_idxs[int((1.-proportion)*n_samples):]\n",
    "\n",
    "def get_batch_count(idxs, batch_size):\n",
    "    batch_count = int(len(idxs)//batch_size)\n",
    "    remained_samples = len(idxs)%batch_size\n",
    "    if remained_samples > 0:\n",
    "        batch_count += 1\n",
    "\n",
    "    return batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idx = idxs[b*batch_size]\n",
    "            X = f['S2'][batch_idx:batch_idx+batch_size, :,:,:]\n",
    "            Y = f['TOP_LANDCOVER'][batch_idx:batch_idx+batch_size, :]\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53606\n"
     ]
    }
   ],
   "source": [
    "idxs = get_idxs(PATH_DATA)\n",
    "shuffled_idxs = shuffle_idx(idxs)\n",
    "train_idxs, val_idxs = split_train_val(shuffled_idxs, 0.2)\n",
    "\n",
    "print(len(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen = generator(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341 336\n"
     ]
    }
   ],
   "source": [
    "print(train_batch_count, val_batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = h5.File(PATH_DATA)['TOP_LANDCOVER']\n",
    "images = h5.File(PATH_DATA)['S2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(23)\n",
    "lbl = np.zeros(len(label))\n",
    "\n",
    "for idx, value in enumerate(label):\n",
    "    counts[int(value)] += 1\n",
    "    lbl[idx] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc000315e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(np.arange(len(counts)), counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  20.0\n",
       "1  20.0\n",
       "2  20.0\n",
       "3  20.0\n",
       "4  20.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_lbl = pd.DataFrame(lbl)\n",
    "pd_lbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (16,16,4)\n",
    "\n",
    "dropout_rate=0.5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(23, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=1341, epochs=10, verbose=1, validation_data=<generator..., validation_steps=1000)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1341/1341 [==============================] - 34s 25ms/step - loss: 3.4855 - acc: 0.0758 - top_3_accuracy: 0.2197 - top_5_accuracy: 0.3554 - val_loss: 2.8571 - val_acc: 0.1089 - val_top_3_accuracy: 0.2641 - val_top_5_accuracy: 0.4033\n",
      "Epoch 2/10\n",
      "1341/1341 [==============================] - 33s 24ms/step - loss: 2.9945 - acc: 0.0972 - top_3_accuracy: 0.2718 - top_5_accuracy: 0.4261 - val_loss: 2.8367 - val_acc: 0.0970 - val_top_3_accuracy: 0.3132 - val_top_5_accuracy: 0.4503\n",
      "Epoch 3/10\n",
      "1341/1341 [==============================] - 33s 24ms/step - loss: 2.6816 - acc: 0.1435 - top_3_accuracy: 0.3526 - top_5_accuracy: 0.5158 - val_loss: 3.1044 - val_acc: 0.0740 - val_top_3_accuracy: 0.2535 - val_top_5_accuracy: 0.4142\n",
      "Epoch 4/10\n",
      "1341/1341 [==============================] - 33s 25ms/step - loss: 2.4689 - acc: 0.1950 - top_3_accuracy: 0.4253 - top_5_accuracy: 0.5945 - val_loss: 3.2579 - val_acc: 0.0613 - val_top_3_accuracy: 0.2157 - val_top_5_accuracy: 0.3647\n",
      "Epoch 5/10\n",
      "1341/1341 [==============================] - 32s 24ms/step - loss: 2.3019 - acc: 0.2337 - top_3_accuracy: 0.4866 - top_5_accuracy: 0.6578 - val_loss: 3.6334 - val_acc: 0.0683 - val_top_3_accuracy: 0.2332 - val_top_5_accuracy: 0.3862\n",
      "Epoch 6/10\n",
      "1341/1341 [==============================] - 34s 25ms/step - loss: 2.1670 - acc: 0.2637 - top_3_accuracy: 0.5464 - top_5_accuracy: 0.7224 - val_loss: 4.6209 - val_acc: 0.0574 - val_top_3_accuracy: 0.1833 - val_top_5_accuracy: 0.3115\n",
      "Epoch 7/10\n",
      "1341/1341 [==============================] - 33s 25ms/step - loss: 2.0690 - acc: 0.3007 - top_3_accuracy: 0.5857 - top_5_accuracy: 0.7536 - val_loss: 3.9632 - val_acc: 0.0698 - val_top_3_accuracy: 0.2118 - val_top_5_accuracy: 0.3579\n",
      "Epoch 8/10\n",
      "1341/1341 [==============================] - 34s 25ms/step - loss: 2.0135 - acc: 0.3200 - top_3_accuracy: 0.6093 - top_5_accuracy: 0.7773 - val_loss: 5.2868 - val_acc: 0.0610 - val_top_3_accuracy: 0.1808 - val_top_5_accuracy: 0.3107\n",
      "Epoch 9/10\n",
      "1341/1341 [==============================] - 33s 25ms/step - loss: 1.9596 - acc: 0.3294 - top_3_accuracy: 0.6231 - top_5_accuracy: 0.7974 - val_loss: 5.4377 - val_acc: 0.0526 - val_top_3_accuracy: 0.1637 - val_top_5_accuracy: 0.2908\n",
      "Epoch 10/10\n",
      "1341/1341 [==============================] - 32s 24ms/step - loss: 1.9172 - acc: 0.3448 - top_3_accuracy: 0.6422 - top_5_accuracy: 0.8043 - val_loss: 5.3923 - val_acc: 0.0661 - val_top_3_accuracy: 0.1950 - val_top_5_accuracy: 0.3193\n"
     ]
    }
   ],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.001)\n",
    "optim = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', top_3_accuracy, top_5_accuracy ])\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_batch_count, epochs=10, verbose=1, validation_data=val_gen, nb_val_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction routines\n",
    "\n",
    "In order to submit a result here are some gits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def prediction_generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = f['S2'][batch_idxs, :,:,:]\n",
    "        yield np.array(X)\n",
    "\n",
    "# def build_h5_pred_file(pred, h5_output_path):\n",
    "#     if os.path.exists(h5_output_path):\n",
    "#         os.remove(h5_output_path)\n",
    "#     f = h5.File(h5_output_path, 'w')\n",
    "#     top_landcover_submit = f.create_dataset(\"TOP_LANDCOVER\", (len(pred), 1), maxshape=(None, 1))equi\n",
    "#     top_landcover_submit[:, 0] = pred\n",
    "#     f.close()\n",
    "#     4\n",
    "#     return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 4s 13ms/step\n",
      "10752\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(val_gen, steps=val_batch_count, verbose=1)\n",
    "print(len(prediction))\n",
    "#to dataframe to csv index = ID colonne TOP_LANDCOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "1486/7554 [====>.........................] - ETA: 20s"
     ]
    }
   ],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction = model.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction))\n",
    "# build_h5_pred_file(np.argmax(prediction, axis = 1), PATH_SUBMIT)\n",
    "panda_prediction = pd.DataFrame(np.argmax(prediction, axis = 1))\n",
    "panda_prediction.columns = ['TOP_LANDCOVER']\n",
    "panda_prediction.head()\n",
    "# panda_prediction.describe()\n",
    "panda_prediction.to_csv(PATH_SUBMIT, index_label = 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "        yield keras.utils.np_utils.to_categorical(np.array(Y), 23)\n",
    "\n",
    "gt_gen = gt_generator(PATH_PREDICT_WITH_GT, BATCH_SIZE, pred_idx)\n",
    "gt = []\n",
    "for elem in gt_gen:\n",
    "    gt.append(elem)\n",
    "gt = np.vstack(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_confusion_matrix(confusion_matrix, classes):\n",
    "    real_classes = []\n",
    "    for c in range(len(classes)):\n",
    "        if np.sum(confusion_matrix[:,c])+np.sum(confusion_matrix[c, :]) != 0:\n",
    "            real_classes.append(c)\n",
    "    real_confusion_matrix = np.empty((len(real_classes), len(real_classes)))  \n",
    "    for c_index in range(len(real_classes)):\n",
    "        real_confusion_matrix[c_index,:] = confusion_matrix[real_classes[c_index], real_classes]\n",
    "    return real_confusion_matrix, real_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = np.argmax(gt, axis=1)\n",
    "y_pred = np.argmax(prediction, axis = 1)\n",
    "\n",
    "real_cnf_matrix, real_classes = clean_confusion_matrix(confusion_matrix(y_true, y_pred, labels= range(23)), range(23))\n",
    "plot_confusion_matrix(real_cnf_matrix, classes = real_classes, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
